name: test
mode: test

batch_size: 1

model:
  input_dim: 300
  output_dim: 1
  n_d: 64  # Dimension of the prediction layer
  n_a: 64  # Dimension of the attention layer
  n_steps: 10
  gamma: 1.3
  cat_idxs: []
  cat_dims: []
  cat_emb_dim: 1
  n_independent: 2
  n_shared: 2
  epsilon: 1e-15
  virtual_batch_size: 128
  momentum: 0.02
  mask_type: "sparsemax"